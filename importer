#!/usr/bin/env python

import argparse
from contextlib import contextmanager
import fileinput
from hashlib import sha1
import _pickle as pickle
import struct
import sys

from util import COL_FMT
COL_NAMES = ['STB', 'TITLE', 'PROVIDER', 'DATE', 'REV', 'VIEW_TIME']


def serialize(rec):
    def tr_str(s):
        return [bytes(e, 'utf-8') for e in s]
    def tr_date(s):
        year, month, day = [int(s) for s in s.split('-')]
        return [year << 9 | month << 5 | day]
    def tr_rev(s):
        return [float(s)]
    def tr_view_time(s):
        hours, minutes = [int(e) for e in s.split(':')]
        return [hours * 60 + minutes]

    cols = (
        tr_str([rec['STB'], rec['TITLE'], rec['PROVIDER']])
        + tr_date(rec['DATE'])
        + tr_rev(rec['REV'])
        + tr_view_time(rec['VIEW_TIME'])
    )
    return struct.pack(COL_FMT, *cols)

@contextmanager
def load_index(fname):
    try:
        with open(fname, 'rb') as index_file:
            index = pickle.load(index_file)
    except FileNotFoundError:
        index = {}
    yield index
    with open(fname, 'wb') as index_file:
        pickle.dump(index, index_file)

def gen_key(rec):
    return sha1(
        (rec['STB']+rec['TITLE']+rec['DATE']).encode()
    ).digest()

def upsert(db_file, index, rec):
    key = gen_key(rec)
    value = serialize(rec)
    pos = index.get(key)

    if pos is not None:
        end_pos = db_file.tell()
        db_file.seek(pos)
        db_file.write(value)
        db_file.seek(end_pos)
    else:
        index[key] = db_file.tell()
        db_file.write(value)

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument("name", help="name of database")
    args = parser.parse_args()

    db_fname = args.name+'.bin'
    index_fname = args.name+'.idx'

    with open(db_fname, 'w+b') as db_file, load_index(index_fname) as index:
        for line in fileinput.input('-'):
            cols = line.strip().split('|')
            if fileinput.isfirstline():
                col_names = cols
                assert(col_names == COL_NAMES)
                continue
            rec = dict(zip(col_names, cols))
            upsert(db_file, index, rec)

# Records in the datastore should be unique by STB, TITLE and DATE.
# Subsequent imports with the same logical record should overwrite
# the earlier records.
